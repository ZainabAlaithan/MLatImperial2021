{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kaggle_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yandexdataschool/MLatImperial2021/blob/master/02_lab/kaggle_challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVS9Ysjf_3Om"
      },
      "source": [
        "# Set up variables and download data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TegjGrHdBbvu"
      },
      "source": [
        "Register on [kaggle](https://www.kaggle.com) and accept the [competition](https://www.kaggle.com/t/e69c3ea6e14d4b34b0cc608f80691676) rules."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tk_xLxkyB3fh"
      },
      "source": [
        "Go to My Account and under API section click **create new API Token**.\n",
        "Download created kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xem4gLJRCG1o"
      },
      "source": [
        "Upload this file to your google drive root folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOCBykoqCTCW"
      },
      "source": [
        "Now execute the following magic. - It installs kaggle, mounts google drive and downloads data from competition to you drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNVBlzYo74g-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43d10117-0bbc-4c80-9957-cfdf7ff6206f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9it6I6mJ8D0N"
      },
      "source": [
        "!mkdir /root/.kaggle\n",
        "!cp /content/gdrive/My\\ Drive/kaggle.json /root/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!ls -l /root/.kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4cp_qct_v_y"
      },
      "source": [
        "DATA_PATH = \"/content/gdrive/My Drive/mlimperial2021-predict-the-house-price\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBSB_0WQCv9n"
      },
      "source": [
        "ls /content/gdrive/My\\ Drive/mlimperial2021-predict-the-house-price"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1PUcjpmFJAs"
      },
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOs-l71b8EgR"
      },
      "source": [
        "#!kaggle config set -n path -v /content\n",
        "!kaggle competitions download -c mlimperial2021-predict-the-house-price -p '/content/gdrive/My Drive/mlimperial2021-predict-the-house-price'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95rwAUYeG3da"
      },
      "source": [
        "!unzip -q /content/gdrive/My\\ Drive/mlimperial2021-predict-the-house-price/mlimperial2021-predict-the-house-price.zip -d /content/gdrive/My\\ Drive/mlimperial2021-predict-the-house-price/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qpk_2c3GOtE"
      },
      "source": [
        "ls /content/gdrive/My\\ Drive/mlimperial2021-predict-the-house-price"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a8HaEMe_Ffs"
      },
      "source": [
        "# https://www.kaggle.com/t/e69c3ea6e14d4b34b0cc608f80691676"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4twUlePA-tJ"
      },
      "source": [
        "### Metric\n",
        "\n",
        "For regression task we can use the most common Mean Squared Error(MSE). However, sometimes its better to use logarithmic error. In this challenge, we will use RMSLE - root mean square logarithmic error:\n",
        "\n",
        "$$\n",
        "RMSLE = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} [\\log(y_i + 1) - \\log(p_i + 1)]^2},\n",
        "$$\n",
        "\n",
        "where $y_i$ is true value and $p_i$ is a predicted value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Z-MTx2FB3c1"
      },
      "source": [
        "# Grading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqB6ygyQDSaz"
      },
      "source": [
        "Your task is to try as many techniques that you have learned this week as possible.\n",
        "\n",
        "\n",
        "The outcome of your work should be a small table with results, i.e Method - parameters tuned with CV - score + features created on top of exiting ones. The table should be accompanied by a small report of your workflow and reasoning. Also, you need to send the code.\n",
        "\n",
        "\n",
        "The archive with the files should be sent to mlicl-2021-seminars@yandex.ru with the topic: Surname_name_kaggle_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_TF_I3071k_"
      },
      "source": [
        "### The total amount of points is 10. You will get additional points based on your final ranking\n",
        "\n",
        "- 1 Point. Find correlated features in the train.csv and macro.csv. Try to run linear regression when you remove this features. What do you observe?\n",
        "- 1 Point. Try to run various linear methods such Ridge, ElasticNet and more. Grid search parameters.\n",
        "- 1 Point. Work with missed values. Try to impute them, remove them, or someshow other use clustering technic to fill in missed values with the best value.\n",
        "- 1 Point. Work with categorial features. Find them. Try to one-hot encode them. Does this improves your score? Try to use standard techniques to work with them, such as counting them, calculating frequency, inverted frequency.\n",
        "- 1 Point. Work with the datastamps. What information can you extract from them? Can you come up with some date based features?\n",
        "- 1 Point. Try to find badly defined features and outliers in the dataset. Remove them. Did it help?\n",
        "- 1 Point. Try using PCA/SVD. Is it usefull? Why?\n",
        "- 1 Point. Create your own features and explain, why did you decide to create those particular ones. Did they make score better?\n",
        "- 1 Point. Apply decision tree, random forest, boosting based algos. Grid search parameters.\n",
        "- 1 Point. Estimate feature importances. Try to remove bad features. Which difference did you notice in comparison when you remove correlated features? \n",
        "- 1 Point. Use stacking and blending of the models trained above? Does it improve your score?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20He9w3471lA"
      },
      "source": [
        "## Bonus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hg4sDAMr71lB"
      },
      "source": [
        "Beat medium baseline and we will give you +3 points :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_3xbCC_CQlT"
      },
      "source": [
        "# Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG_2DJplCTah"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_log_error,mean_squared_error\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzyH18tHCWb7"
      },
      "source": [
        "data = pd.read_csv(os.path.join(DATA_PATH, 'X_train.csv'), parse_dates=['timestamp'])\n",
        "test = pd.read_csv(os.path.join(DATA_PATH, 'X_test.csv'), parse_dates=['timestamp'])\n",
        "macro = pd.read_csv(os.path.join(DATA_PATH, \"macro.csv\"), parse_dates=['timestamp'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5RtbIcDC8w2"
      },
      "source": [
        "data.shape, test.shape, macro.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fp5QBtq4CraP"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_r4_pAmDCQS"
      },
      "source": [
        "macro.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArkktrP1DH0P"
      },
      "source": [
        "As you can see, the timestamp is important here, because it will define the various variables, that change with time, for example, gdp or mortgage rate. Lets, for example, merge train, test,the data on the timestamp."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-5k4fRrD6Wl"
      },
      "source": [
        "y_train = data[\"price_doc\"]\n",
        "\n",
        "data.drop(['id', 'price_doc'], axis=1, inplace=True)\n",
        "\n",
        "# num_train = len(X_train)\n",
        "# X_all = pd.concat([X_train, X_test])\n",
        "\n",
        "\n",
        "X_all = pd.merge_ordered(data, macro, on='timestamp', how='left')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaVTKO2GFNWy"
      },
      "source": [
        "X_all.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcLPzlCNFWnJ"
      },
      "source": [
        "A small hint - do we really need all 389 columns? What is the distribution of the predicted data?\n",
        "\n",
        "For now, lets split the training set to train/test and fit simpliest linear model on top of it. But before that we must get rid of NaNs!, beacause not algorithms can deal with them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSvLVJ1uFfZC"
      },
      "source": [
        "X_all.fillna(0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifBIe6G9FAWT"
      },
      "source": [
        "training_ind, validation_ind = train_test_split(range(len(X_all)), random_state=11, train_size=0.10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tf_2AwktF3k_"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZRj7zHsGXRs"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_all.iloc[training_ind])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X89pgqYiGhCh"
      },
      "source": [
        "# Error! Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XHYnVf1Gk4N"
      },
      "source": [
        "Because we have there are exists categorial values in the table. For now, we will just drop them, but you should not! They might be important for the prediction result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abeE8QI3GyYi"
      },
      "source": [
        "df_numeric = X_all.select_dtypes(exclude=['object'])\n",
        "df_numeric.drop([\"timestamp\"], inplace=True, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYkJ4myIG6TK"
      },
      "source": [
        "df_numeric.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X34Z46JRHAUR"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(df_numeric.iloc[training_ind])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgXgg25FHbnA"
      },
      "source": [
        "predictor = Ridge()\n",
        "predictor.fit(X_train, np.log1p(y_train[training_ind]))\n",
        "\n",
        "X_test = scaler.transform(df_numeric.iloc[validation_ind])\n",
        "mean_squared_error(predictor.predict(X_test), np.log1p(y_train[validation_ind]), squared=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWnHb-NIHDMB"
      },
      "source": [
        "%%time\n",
        "\n",
        "param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10]}\n",
        "\n",
        "gscv = GridSearchCV(predictor, param_grid, scoring='neg_root_mean_squared_error', cv=3, n_jobs=-1, verbose=1)\n",
        "gscv.fit(X_train, np.log1p(y_train[training_ind]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKbsPBJ1HFtP"
      },
      "source": [
        "gscv.cv_results_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWqhV4IfRTX3"
      },
      "source": [
        "## Now we can fit on all the data and make a prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDtVW5AtRnPX"
      },
      "source": [
        "Refit model with best parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCSb4-WpRCm9"
      },
      "source": [
        "predictor = Ridge(alpha=1)\n",
        "predictor.fit(X_train, np.log1p(y_train[training_ind]))\n",
        "\n",
        "X_test = scaler.transform(df_numeric.iloc[validation_ind])\n",
        "mean_squared_error(predictor.predict(X_test), np.log1p(y_train[validation_ind]), squared=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsswrvuHRh7N"
      },
      "source": [
        "# Make predictions on the test set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcGXd4kRSdV6"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crq6J0L5R243"
      },
      "source": [
        "pred_ids = test['id']\n",
        "test.drop(['id'], axis=1, inplace=True)\n",
        "X_predict = pd.merge_ordered(test, macro, on='timestamp', how='left')\n",
        "X_predict.fillna(0, inplace=True)\n",
        "X_predict = X_predict[df_numeric.columns]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMRVrpd4RRa2"
      },
      "source": [
        "predictions = np.expm1(predictor.predict(scaler.transform(X_predict)))\n",
        "predictions = pd.DataFrame(predictions, columns=[\"price_doc\"])\n",
        "predictions = pd.concat([pred_ids, predictions], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccA7_auvS8lh"
      },
      "source": [
        "predictions.to_csv(os.path.join(DATA_PATH, \"predictions.csv\"), index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wOSSUbBV2Ka"
      },
      "source": [
        "!head -n 5 '/content/gdrive/My Drive/mlimperial2021-predict-the-house-price/predictions.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-62qk7aIWU2R"
      },
      "source": [
        "# Lets use kaggle API again to submit results\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_2E9T8pWLlT"
      },
      "source": [
        "!kaggle competitions submit -c mlimperial2021-predict-the-house-price -f \"{DATA_PATH}/predictions.csv\" -m \"Message\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}