{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab7_GANs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yandexdataschool/MLatImperial2021/blob/master/07_lab/lab7_GANs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKatwHToL7vN"
      },
      "source": [
        "# Generative adversarial networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY5JMnzgMb4P"
      },
      "source": [
        "Let's do our usual imports + use a tool to download the dataset we'll use today:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nereROxJhE4B"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "from tqdm import tqdm\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYAIjRM1CLnq"
      },
      "source": [
        "The code below will download and preprocess the dataset we'll work with today:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP74Sd_tCD5R"
      },
      "source": [
        "lfw = tfds.image_classification.LFW()\n",
        "lfw.download_and_prepare()\n",
        "ds = lfw.as_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMt5WWu_CFdo"
      },
      "source": [
        "def get_img(x):\n",
        "  return x['image'][80:-80,80:-80]\n",
        "\n",
        "data = np.array([\n",
        "  np.array(Image.fromarray(img.numpy()).resize((36, 36)))\n",
        "  for img in tqdm(ds['train'].map(get_img))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZr3EJGQCW9w"
      },
      "source": [
        "Let's have a look at the shape of the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDYZz-AwCU2R"
      },
      "source": [
        "print(\"shape:\", data.shape)\n",
        "print(\"min, max:\", data.min(), data.max())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9S6ZuQaMntn"
      },
      "source": [
        "So far our data has the following shape: (n_images, height, width, n_channels). PyTorch convolutional layers want the channels dimension to be the second one (axis=1), so let's transpose (and normalize) the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZopvYBFmtSl"
      },
      "source": [
        "data = data.transpose(0, 3, 1, 2).astype(np.float32) / 255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "958mLZ1dNPZD"
      },
      "source": [
        "And here's a function to plot a (optionally random) subset of images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqtnOTerna5R"
      },
      "source": [
        "def plot_mn(images, m=5, n=5, shuffle=True):\n",
        "  if shuffle:\n",
        "    images = images[np.random.permutation(len(images))[:m * n]]\n",
        "  h, w = images.shape[2:]\n",
        "  images = images[:m*n].reshape(m, n, *images.shape[1:]).transpose(0, 1, 3, 4, 2) # plotting requires channels last\n",
        "  images = images.transpose(0, 2, 1, 3, 4).reshape(m * h, n * w, -1)\n",
        "  plt.imshow(images)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plot_mn(data)\n",
        "plt.axis('off');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9Pg3gYBN05p"
      },
      "source": [
        "Finally, let's import torch and define the Reshape layer (same as in the convolutions notebook):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z7YAPGxp2Xl"
      },
      "source": [
        "import torch\n",
        "\n",
        "class Reshape(torch.nn.Module):\n",
        "  def __init__(self, *shape):\n",
        "    super(Reshape, self).__init__()\n",
        "    self.shape = shape\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x.reshape(x.shape[0], *self.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORVT4PnCN_0h"
      },
      "source": [
        "Now, we'll take off from a very simple generator and discriminator:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Db-LPTKOIhf"
      },
      "source": [
        "latent_dims = 128\n",
        "dropout_rate = 0.1\n",
        "\n",
        "generator = torch.nn.Sequential(\n",
        "    torch.nn.Linear(latent_dims, 64),\n",
        "    torch.nn.ELU(),\n",
        "    torch.nn.Dropout(p=dropout_rate),\n",
        "    torch.nn.Linear(64, 3 * 36 * 36),\n",
        "    torch.nn.ELU(),\n",
        "    Reshape(3, 36, 36)\n",
        ").cuda()\n",
        "\n",
        "discriminator = torch.nn.Sequential(\n",
        "    Reshape(3 * 36 * 36),\n",
        "    torch.nn.Linear(3 * 36 * 36, 128),\n",
        "    torch.nn.ELU(),\n",
        "    torch.nn.Dropout(p=dropout_rate),\n",
        "    torch.nn.Linear(128, 1),\n",
        ").cuda()\n",
        "\n",
        "def get_n_params(model):\n",
        "  return sum(p.reshape(-1).shape[0] for p in model.parameters())\n",
        "\n",
        "print('generator params:', get_n_params(generator))\n",
        "print('discriminator params:', get_n_params(discriminator))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOiD7VoLPfIz"
      },
      "source": [
        "Then, we need a function to sample real and fake images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKuzv2Ok9vAy"
      },
      "source": [
        "def sample_images(batch_size):\n",
        "  ids = np.random.choice(len(data), size=batch_size)\n",
        "  return torch.tensor(data[ids]).cuda()\n",
        "\n",
        "def sample_fake(batch_size):\n",
        "  noise = torch.randn(batch_size, latent_dims).cuda()\n",
        "  return generator(noise)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyYWtgV4Pn3G"
      },
      "source": [
        "Let's have a look what we can generate before any training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l_ju5AeyffR"
      },
      "source": [
        "generator.eval()\n",
        "imgs = sample_fake(25).cpu().detach().numpy()\n",
        "plt.figure(figsize=(8, 8))\n",
        "plot_mn(imgs.clip(0, 1))\n",
        "plt.axis('off')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLv6NgnbP2iO"
      },
      "source": [
        "Ok, now that we have our model defined, we need our loss functions. Historically the first loss used in GANs is the cross-entropy that we already used so many times:\n",
        "$$\\mathscr{L}^{\\text{discr}} =\n",
        "-\\text{E}\\left[logD(x_{real})\\right]\n",
        "-\\text{E}\\left[log(1 - D(x_{fake}))\\right] \n",
        "$$\n",
        "\n",
        "And hence for the generator the loss is:\n",
        "\n",
        "$$\\mathscr{L}^{\\text{gen}} =\n",
        "-\\text{E}\\left[logD(x_{fake})\\right]$$\n",
        "\n",
        "Note that here $D(x)$ is the probability the discriminator assigns to $x$ to be from the real dataset, so it's $\\sigma($ `discriminator` $(x))$.\n",
        "\n",
        "Try implementing these loss functions below. Note that $1-\\sigma(x)=\\sigma(-x)$. You should use the `logsigmoid` as a stable realization of $log\\cdot\\sigma(x)$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVYlJGqlTJLJ"
      },
      "source": [
        "logsigmoid = torch.nn.functional.logsigmoid\n",
        "\n",
        "def generator_loss(fake):\n",
        "  return <YOUR CODE HERE>\n",
        "  \n",
        "def discriminator_loss(real, fake):\n",
        "  return <YOUR CODE HERE>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YP1jCl68UGs_"
      },
      "source": [
        "Let's do some more set-up and run the learning process:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIirtIXRkpuD"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "generator_losses = []\n",
        "discriminator_losses = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCLeJ9SQToLs"
      },
      "source": [
        "optimizer_generator = \\\n",
        "    torch.optim.RMSprop(generator.parameters(), lr=0.001)\n",
        "optimizer_discriminator = \\\n",
        "    torch.optim.RMSprop(discriminator.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRPr9l4tTqIN"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "for i in range(1000):\n",
        "  # Since our models are updated in turns,\n",
        "  # we first set the discriminator to train,\n",
        "  # while the generator is in the eval mode\n",
        "  generator.eval()\n",
        "  discriminator.train()\n",
        "  \n",
        "  # Several discriminator updates per step:\n",
        "  for j in range(5):\n",
        "    # Sampling reals and fakes\n",
        "    real = sample_images(batch_size)\n",
        "    fake = sample_fake(batch_size)\n",
        "    \n",
        "    # Calculating the loss\n",
        "    loss = discriminator_loss(real, fake)\n",
        "    \n",
        "    # Doing our regular optimization step for the discriminator\n",
        "    discriminator.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer_discriminator.step()\n",
        "\n",
        "  # Remember the value of discriminator loss for plotting\n",
        "  discriminator_losses.append(loss.item())\n",
        "\n",
        "  # Now it's generator's time to learn:\n",
        "  generator.train()\n",
        "  discriminator.eval()\n",
        "\n",
        "  loss = generator_loss(sample_fake(batch_size))\n",
        "  generator_losses.append(loss.item())\n",
        "  generator.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer_generator.step()\n",
        "\n",
        "  if i % 20 == 0:\n",
        "    generator.eval()\n",
        "    imgs = sample_fake(25).cpu().detach().numpy()\n",
        "    \n",
        "    clear_output(wait=True)\n",
        "\n",
        "    plt.figure(figsize=(16, 8))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(generator_losses    , label='generator loss')\n",
        "    plt.plot(discriminator_losses, label='discriminator loss')\n",
        "    plt.legend()\n",
        "    \n",
        "    plt.subplot(1, 2, 2)\n",
        "    plot_mn(imgs.clip(0, 1))\n",
        "    plt.axis('off')\n",
        "    plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUWQQK7_VRrR"
      },
      "source": [
        "Seems like it's working! Now try to impelment some convolutional architechtures to make our model more expressive.\n",
        "\n",
        "You might face some instabilities as you go. The simplest regularization that can be done is **adding some random noize to the discriminator's input**.\n",
        "\n",
        "Another good stabilization is adding a **discriminator gradient L2 penalty for real images only** (see this paper: https://arxiv.org/pdf/1801.04406.pdf):\n",
        "\n",
        "```\n",
        "def discriminator_penalty(real):\n",
        "  real.requires_grad = True\n",
        "  scores = discriminator(real)\n",
        "  grad_params = torch.autograd.grad(scores.mean(), real,\n",
        "                                    create_graph=True)\n",
        "  penalty = sum((grad**2).sum() for grad in grad_params)\n",
        "  return penalty\n",
        "```\n",
        "\n",
        "\n",
        "You can also use **decreasing learning rate**:\n",
        "\n",
        "```\n",
        "# multiply the learning rate by 0.999 each 10 steps:\n",
        "scheduler_d = torch.optim.lr_scheduler.StepLR(optimizer_discriminator, step_size=10, gamma=0.999)\n",
        "scheduler_g = torch.optim.lr_scheduler.StepLR(optimizer_generator    , step_size=10, gamma=0.999)\n",
        "\n",
        "# ...\n",
        "\n",
        "# In the training loop:\n",
        "  scheduler_d.step()\n",
        "  scheduler_g.step()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lq21nj1DJAf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}